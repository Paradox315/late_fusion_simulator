{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T13:14:17.726085Z",
     "start_time": "2025-02-22T13:14:17.721852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def sinkhorn(scores, eps=0.1, n_iter=3):\n",
    "    # 将代价矩阵通过 softmax 转换为初始概率分布\n",
    "    scores = torch.tensor(scores)\n",
    "    n, m = scores.shape\n",
    "    Q = torch.softmax(-scores / eps, dim=1)  # 使用 softmax 归一化\n",
    "    r = torch.ones(n)\n",
    "    c = torch.ones(m) * (n / m)\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        # 行归一化\n",
    "        u = c / Q.sum(dim=0)\n",
    "        Q *= u.unsqueeze(0)\n",
    "        # 列归一化\n",
    "        v = r / Q.sum(dim=1)\n",
    "        Q *= v.unsqueeze(1)\n",
    "    return Q.numpy()\n",
    "\n",
    "\n",
    "x = torch.randn(5, 5)\n",
    "y = sinkhorn(x, eps=0.05, n_iter=20)\n",
    "y.sum(0), y.sum(1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/cpd22g_13gj3f7ylq5d397jh0000gn/T/ipykernel_12218/901252112.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scores = torch.tensor(scores)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.97665113, 0.9992993 , 1.0000001 , 0.99942327, 1.0246263 ],\n",
       "       dtype=float32),\n",
       " array([0.99999994, 1.        , 1.        , 1.        , 1.        ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T13:14:48.816576Z",
     "start_time": "2025-02-22T13:14:48.810060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sinkhorn_log(scores, eps=0.1, n_iter=3):\n",
    "    \"\"\"\n",
    "    Sinkhorn algorithm in the log domain.\n",
    "    Inputs:\n",
    "      scores: cost matrix (n x m)\n",
    "      eps: temperature parameter\n",
    "      n_iter: number of normalization iterations\n",
    "    Returns:\n",
    "      Q: normalized matrix as torch.Tensor\n",
    "    \"\"\"\n",
    "    scores = torch.tensor(scores)  # ensure tensor conversion\n",
    "    n, m = scores.shape\n",
    "\n",
    "    # Initialize log domain matrix L = log Q = -scores / eps\n",
    "    L = -scores / eps\n",
    "\n",
    "    # Set log scaling factors (r are ones, c are scaled to match the desired sum along columns)\n",
    "    log_r = torch.zeros(n, device=L.device)  # since r=1 => log(1)=0\n",
    "    log_c = torch.log(torch.ones(m, device=L.device) * (n / m))\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        # Normalize columns: compute log sum over rows\n",
    "        logsum_cols = torch.logsumexp(L, dim=0)  # shape: (m,)\n",
    "        log_u = log_c - logsum_cols  # adjustment for columns\n",
    "        # Broadcast addition over columns\n",
    "        L = L + log_u.unsqueeze(0)\n",
    "\n",
    "        # Normalize rows: compute log sum over columns\n",
    "        logsum_rows = torch.logsumexp(L, dim=1)  # shape: (n,)\n",
    "        log_v = log_r - logsum_rows  # adjustment for rows\n",
    "        # Broadcast addition over rows\n",
    "        L = L + log_v.unsqueeze(1)\n",
    "\n",
    "    # Convert back from log-domain\n",
    "    Q = torch.exp(L)\n",
    "    return Q\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "x = torch.randn(5, 5)\n",
    "y = sinkhorn_log(x, eps=0.05, n_iter=20)\n",
    "print(\"Column sums:\", y.sum(dim=0))\n",
    "print(\"Row sums:\", y.sum(dim=1))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column sums: tensor([0.6664, 0.4999, 0.6622, 0.4999, 0.6716])\n",
      "Row sums: tensor([1.0000, 1.0000, 1.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/cpd22g_13gj3f7ylq5d397jh0000gn/T/ipykernel_12218/2668376.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scores = torch.tensor(scores)  # ensure tensor conversion\n"
     ]
    }
   ],
   "execution_count": 93
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
